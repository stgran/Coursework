{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS156 Assignment 4\n",
    "# Support Vector Machines\n",
    "### Soren Gran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from shutil import copyfileobj\n",
    "from six.moves import urllib\n",
    "from sklearn.datasets.base import get_data_home\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MNIST data\n",
    "# Code taken from Professor Sterne on Slack\n",
    "def fetch_mnist(data_home=None):\n",
    "    mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "    data_home = get_data_home(data_home=data_home)\n",
    "    data_home = os.path.join(data_home, 'mldata')\n",
    "    if not os.path.exists(data_home):\n",
    "        os.makedirs(data_home)\n",
    "    mnist_save_path = os.path.join(data_home, \"mnist-original.mat\")\n",
    "    if not os.path.exists(mnist_save_path):\n",
    "        mnist_url = urllib.request.urlopen(mnist_alternative_url)\n",
    "        with open(mnist_save_path, \"wb\") as matlab_file:\n",
    "            copyfileobj(mnist_url, matlab_file)\n",
    "\n",
    "fetch_mnist()\n",
    "mnist = fetch_mldata(\"MNIST original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "3.0\n",
      "8.0\n",
      "3.0\n",
      "8.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = mnist['target']\n",
    "images = mnist['data']\n",
    "\n",
    "# I will choose 3s and 8s because I think they will be more difficult to classify than 1s and 0s\n",
    "indeces = []\n",
    "dep = []\n",
    "indep = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 3 or labels[i] == 8:\n",
    "        indeces.append(i)\n",
    "        dep.append(labels[i])\n",
    "        \n",
    "for j in indeces:\n",
    "    indep.append(images[j])\n",
    "\n",
    "# Let's see a few images\n",
    "numbers = np.random.randint(0, len(dep), 5) # Here I select a few random images\n",
    "images_and_labels = list(zip(indep, dep))\n",
    "\n",
    "\n",
    "for i, j in zip(numbers, range(len(numbers))):\n",
    "    print(dep[i]) # print the label\n",
    "    pixels = indep[i].reshape((28, 28)) # reformat the images\n",
    "    plt.subplot(2, 4, j+1)\n",
    "    plt.imshow(pixels, cmap='gray') # show the images\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(indep, dep, test_size=.75) # split our data into testing and training data\n",
    "# the reason I only used 25% of our data for training is because my SVMs were taking forever to run with 50%\n",
    "# This makes sense based on this quote from the Scikit page:\n",
    "# The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset\n",
    "# more than a couple of 10000 samples.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier with Linear Kernel\n",
    "# Finding the right C with cross validation\n",
    "# I am using a stratified K fold cross validation to determine which C value yields the best results.\n",
    "# I will do the same for the degree in the polynomial SVM\n",
    "for i in [.5, 5, 50, .05]: # I want to try different C values\n",
    "    linear = SVC(C = i, kernel='linear') # activate the SVM with the appropriate C value\n",
    "    print('C = ', i)\n",
    "    linear.fit(X_train, y_train)\n",
    "    predictions = linear.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "\n",
    "# Unfortunately, the results for each C value were all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541454913.335288\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier with Linear Kernel\n",
    "# Now I want to time my model. I will do the same thing for the other kernels.\n",
    "start = time.time()\n",
    "linear = SVC(C = .5, kernel='linear')\n",
    "print(start)\n",
    "linear.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end)\n",
    "predictions = linear.predict(X_test)\n",
    "print('Training time for linear kernel:')\n",
    "print(end - start)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "# Basically I just start a timer right before the training begins and stop it when the classification ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree =  1\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n",
      "Degree =  1\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n",
      "Degree =  1\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.94      0.95      0.94      5337\n",
      "        8.0       0.94      0.93      0.94      5138\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10475\n",
      "\n",
      "0.9392840095465393\n",
      "Degree =  1\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.95      0.95      0.95      5337\n",
      "        8.0       0.94      0.94      0.94      5138\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10475\n",
      "\n",
      "0.9451073985680191\n",
      "Degree =  2\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n",
      "0.9865393794749403\n",
      "Degree =  2\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n",
      "0.9865393794749403\n",
      "Degree =  2\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n",
      "0.9865393794749403\n",
      "Degree =  2\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n",
      "0.9865393794749403\n",
      "Degree =  3\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.98      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9843436754176611\n",
      "Degree =  3\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.98      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9843436754176611\n",
      "Degree =  3\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.98      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9843436754176611\n",
      "Degree =  3\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.98      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9843436754176611\n",
      "Degree =  4\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.97      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9813842482100239\n",
      "Degree =  4\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.97      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9813842482100239\n",
      "Degree =  4\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.97      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9813842482100239\n",
      "Degree =  4\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.98      5337\n",
      "        8.0       0.99      0.97      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9813842482100239\n",
      "Degree =  5\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.97      0.99      0.98      5337\n",
      "        8.0       0.99      0.96      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9765155131264917\n",
      "Degree =  5\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.97      0.99      0.98      5337\n",
      "        8.0       0.99      0.96      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9765155131264917\n",
      "Degree =  5\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.97      0.99      0.98      5337\n",
      "        8.0       0.99      0.96      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9765155131264917\n",
      "Degree =  5\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.97      0.99      0.98      5337\n",
      "        8.0       0.99      0.96      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "0.9765155131264917\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier with Poly Kernel\n",
    "for i in [1, 2, 3, 4, 5]: # The same cross validation as before, but with the degree of the polynomial\n",
    "    for j in [.5, 5, 50, .05]:\n",
    "        poly = SVC(C = j, kernel='poly', degree = i)\n",
    "        print('Degree = ', i)\n",
    "        print('C = ', j)\n",
    "        poly.fit(X_train, y_train)\n",
    "        predictions = poly.predict(X_test)\n",
    "        print(classification_report(y_test, predictions))\n",
    "        print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541453843.240691\n",
      "1541453844.5102122\n",
      "Training time for poly kernel:\n",
      "1.2695212364196777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier with Poly Kernel\n",
    "# Here we do the same as before.\n",
    "poly = SVC(C = .5, kernel='poly', degree = 2)\n",
    "start = time.time()\n",
    "print(start)\n",
    "poly.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end)\n",
    "predictions = poly.predict(X_test)\n",
    "print('Training time for poly kernel:')\n",
    "print(end - start)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma =  1e-09\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.87      0.93      0.90      5337\n",
      "        8.0       0.93      0.85      0.89      5138\n",
      "\n",
      "avg / total       0.90      0.90      0.89     10475\n",
      "\n",
      "Gamma =  1e-09\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.95      0.95      0.95      5337\n",
      "        8.0       0.95      0.95      0.95      5138\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10475\n",
      "\n",
      "Gamma =  1e-09\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.97      0.96      0.97      5337\n",
      "        8.0       0.96      0.97      0.96      5138\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10475\n",
      "\n",
      "Gamma =  1e-09\n",
      "C =  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sorengran/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  1e-07\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.97      0.98      5337\n",
      "        8.0       0.97      0.98      0.97      5138\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10475\n",
      "\n",
      "Gamma =  1e-07\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.98      0.98      5337\n",
      "        8.0       0.98      0.98      0.98      5138\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10475\n",
      "\n",
      "Gamma =  1e-07\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n",
      "Gamma =  1e-07\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.95      0.96      0.95      5337\n",
      "        8.0       0.95      0.94      0.95      5138\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10475\n",
      "\n",
      "Gamma =  1e-05\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  1e-05\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  1e-05\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  1e-05\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.001\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.001\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.001\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.001\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.1\n",
      "C =  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.1\n",
      "C =  5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.1\n",
      "C =  50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n",
      "Gamma =  0.1\n",
      "C =  0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.51      1.00      0.68      5337\n",
      "        8.0       0.00      0.00      0.00      5138\n",
      "\n",
      "avg / total       0.26      0.51      0.34     10475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier with Radial Basis Function Kernel\n",
    "for i in [1e-9, 1e-7, 1e-5, 1e-3, .1]:\n",
    "    for j in [.5, 5, 50, .05]:\n",
    "        print('Gamma = ', i)\n",
    "        print('C = ', j)\n",
    "        rbf = SVC(C = j, kernel = 'rbf', gamma = i)\n",
    "        rbf.fit(X_train, y_train)\n",
    "        predictions = rbf.predict(X_test)\n",
    "        print(classification_report(y_test, predictions))\n",
    "        print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541453956.13411\n",
      "1541453957.539885\n",
      "Training time for RBF kernel:\n",
      "1.4057750701904297\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        3.0       0.98      0.99      0.99      5337\n",
      "        8.0       0.99      0.98      0.99      5138\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier with Radial Basis Function Kernel\n",
    "rbf = SVC(C = 50, kernel='rbf', gamma = 1e-07)\n",
    "start = time.time()\n",
    "print(start)\n",
    "rbf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end)\n",
    "predictions = rbf.predict(X_test)\n",
    "print('Training time for RBF kernel:')\n",
    "print(end - start)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Training Times for 3491 datapoints\n",
    "|Kernel|Training Time (sec)|\n",
    "|------|-------------|\n",
    "|Linear (C = .5)|1.6625|\n",
    "|Poly  (kernel = 2, C = .5)|1.2695|\n",
    "|RBF  (gamma = 1e-07, C = 50) |1.4057|\n",
    "\n",
    "## Error Rates\n",
    "|Kernel|Error Rate (%)|\n",
    "|------|--------------|\n",
    "|Linear (C = .5)|6|\n",
    "|Poly  (kernel = 2, C = .5)|1|\n",
    "|RBF  (gamma = 1e-07, C = 50)|1|\n",
    "\n",
    "I chose 3s and 8s with the intention of making it tough for the SVMs but it still did almost as well as possible. The Polynomial and RBF kernels both resulted in near perfect results.\n",
    "\n",
    "Why didn't changing C affect the Linear kernel's results? C represents the 'penalty parameter of the error term' (according to Scikit's website) so lowering it means we make our model less strict. However, my intuition tells that we were still setting the boundary in the same place each time despite how much error we allowed. The error would affect the width of our road, not the location of the center line. If we had less data, then changing the support vectors like this would probably influence the location of the road, but I think the amount of data we had allowed us to keep the decision boundary in basically the same place despite changing the support vectors.\n",
    "\n",
    "INTERESTING NOTE: I actually did this assignment wrong yesterday and went back today and fixed a lot of issues. However, last night my training times were atrocious. The Poly kernel took 30 seconds to train, which RBF took 300 seconds to train while giving my 50% accuracy results (it latched onto the first number it saw). However, with better parameters, their performance (both accuracy and time) improved drastically."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full Results for Linear Kernel\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "The Linear Kernel had the same performance for all the C values used. I will use C = .5 for the time evaluation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full Results for Poly Kernel\n",
    "\n",
    "Degree =  1\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "Degree =  1\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "Degree =  1\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.94      0.93      0.94      5336\n",
    "        8.0       0.93      0.94      0.93      5139\n",
    "\n",
    "avg / total       0.93      0.93      0.93     10475\n",
    "\n",
    "Degree =  1\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.95      0.95      0.95      5336\n",
    "        8.0       0.95      0.95      0.95      5139\n",
    "\n",
    "avg / total       0.95      0.95      0.95     10475\n",
    "\n",
    "Degree =  2\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.99      0.99      0.99      5336\n",
    "        8.0       0.99      0.99      0.99      5139\n",
    "\n",
    "avg / total       0.99      0.99      0.99     10475\n",
    "BEST\n",
    "Degree =  2\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.99      0.99      0.99      5336\n",
    "        8.0       0.99      0.99      0.99      5139\n",
    "\n",
    "avg / total       0.99      0.99      0.99     10475\n",
    "BEST\n",
    "Degree =  2\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.99      0.99      0.99      5336\n",
    "        8.0       0.99      0.99      0.99      5139\n",
    "\n",
    "avg / total       0.99      0.99      0.99     10475\n",
    "BEST\n",
    "Degree =  2\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.99      0.99      0.99      5336\n",
    "        8.0       0.99      0.99      0.99      5139\n",
    "\n",
    "avg / total       0.99      0.99      0.99     10475\n",
    "BEST\n",
    "Degree =  3\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.99      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  3\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.99      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  3\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.99      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  3\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.99      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  4\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.98      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  4\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.98      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  4\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.98      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  4\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.98      0.98      5336\n",
    "        8.0       0.98      0.98      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  5\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.97      0.98      0.98      5336\n",
    "        8.0       0.98      0.97      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  5\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.97      0.98      0.98      5336\n",
    "        8.0       0.98      0.97      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  5\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.97      0.98      0.98      5336\n",
    "        8.0       0.98      0.97      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Degree =  5\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.97      0.98      0.98      5336\n",
    "        8.0       0.98      0.97      0.98      5139\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "\n",
    "As you can see, the Polynomial kernel performed well across the board. However, its performance was maximized with Degree = 2 for all the C values we tested. Therefore, we will use Degree = 2, C = .5 for our timing.\n",
    "I will use its maximum performance parameters, Degree =  2 and C =  0.5, for the time evaluation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full Results for RBF Kernel\n",
    "Gamma =  1e-09\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.87      0.93      0.90      5337\n",
    "        8.0       0.93      0.85      0.89      5138\n",
    "\n",
    "avg / total       0.90      0.90      0.89     10475\n",
    "\n",
    "Gamma =  1e-09\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.95      0.95      0.95      5337\n",
    "        8.0       0.95      0.95      0.95      5138\n",
    "\n",
    "avg / total       0.95      0.95      0.95     10475\n",
    "\n",
    "Gamma =  1e-09\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.97      0.96      0.97      5337\n",
    "        8.0       0.96      0.97      0.96      5138\n",
    "\n",
    "avg / total       0.96      0.96      0.96     10475\n",
    "\n",
    "Gamma =  1e-09\n",
    "C =  0.05\n",
    "/Users/sorengran/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  1e-07\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.97      0.98      5337\n",
    "        8.0       0.97      0.98      0.97      5138\n",
    "\n",
    "avg / total       0.97      0.97      0.97     10475\n",
    "\n",
    "Gamma =  1e-07\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.98      0.98      5337\n",
    "        8.0       0.98      0.98      0.98      5138\n",
    "\n",
    "avg / total       0.98      0.98      0.98     10475\n",
    "\n",
    "Gamma =  1e-07\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.98      0.99      0.99      5337\n",
    "        8.0       0.99      0.98      0.99      5138\n",
    "\n",
    "avg / total       0.99      0.99      0.99     10475\n",
    "BEST\n",
    "Gamma =  1e-07\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.95      0.96      0.95      5337\n",
    "        8.0       0.95      0.94      0.95      5138\n",
    "\n",
    "avg / total       0.95      0.95      0.95     10475\n",
    "\n",
    "Gamma =  1e-05\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  1e-05\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  1e-05\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  1e-05\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  0.001\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  0.001\n",
    "C =  5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  0.001\n",
    "C =  50\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  0.001\n",
    "C =  0.05\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  0.1\n",
    "C =  0.5\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        3.0       0.51      1.00      0.68      5337\n",
    "        8.0       0.00      0.00      0.00      5138\n",
    "\n",
    "avg / total       0.26      0.51      0.34     10475\n",
    "\n",
    "Gamma =  0.1\n",
    "C =  5\n",
    "\n",
    "\n",
    "For the RBF Kernel, the classification broke down when Gamma got to 1e-5 and bigger. It also broke down when Gamma =  1e-09, C =  0.05. It appears that when it breaks, it classifies everything as the first thing it sees. In these cases, it saw 3 first.\n",
    "I will use its maximum performance parameters, Gamma =  1e-07 and C =  50, for the time evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
