{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA/LDA Assignment\n",
    "## CS156 // Professor Sterne\n",
    "## Soren Gran // 10/22/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to build a way to make our images all the same size arrays so we can build a model for them\n",
    "# What kind of data cleaning do we want to do? We want to make sure the datasets do not share any images.\n",
    "# It would also be helpful to choose images that have the same backgrounds so our classifier can focus on what\n",
    "# is likely most important: the center of the image.\n",
    "\n",
    "# Originally I was going to do a men-women classifier but the images are really terrible for classification\n",
    "# compared to the jersey-shirt images.\n",
    "\n",
    "def img_to_array(img):\n",
    "    img = img.resize((138,138)) # making the image the same size\n",
    "    img = list(img.getdata()) # put the image info into a list. Now we have a list of lists:\n",
    "                            # For an image, we have a list of 138**2 = 19044 lists of the R(ed)G(reeen)B(lue) data\n",
    "                            # (3 numbers between 0 and 255 because there are 256 levels for each color)\n",
    "    img = list(map(list, img)) # Instead of a list of lists, we want a list of coordinates that sklearn can take\n",
    "    img = np.array(img)\n",
    "    s = img.shape[0] * img.shape[1] # img.shape gives us the shape of the dataset as if we had these in rows-columns\n",
    "                            # In this case, we have an array of 19044 data of 3 coordinates, so our shape is 19044, 3\n",
    "                            # Therefore, s gives us the total number of data in the array.\n",
    "    img_wide = img.reshape(1, s) # This puts all our data into one array\n",
    "    return img_wide[0]\n",
    "\n",
    "jerseydir = listdir('/Users/sorengran/Downloads/Jersey')\n",
    "shirtdir = listdir('/Users/sorengran/Downloads/Shirt')\n",
    "\n",
    "visited = []\n",
    "\n",
    "jerseys = []\n",
    "for image in jerseydir:\n",
    "    img = Image.open('/Users/sorengran/Downloads/Jersey/' + image).convert('RGB')\n",
    "    if img.getpixel((0,0)) == (255,255,255): # first we check to make sure the top left corner pixel is white\n",
    "                                # We hope this means the background is white (this will not always be true)\n",
    "        new_image = img_to_array(img)\n",
    "        jerseys.append(new_image)\n",
    "        visited.append(hash(str(new_image[25000:26000])))\n",
    "\n",
    "doubles = []\n",
    "shirts = []\n",
    "for image in shirtdir:\n",
    "        img = Image.open('/Users/sorengran/Downloads/Shirt/' + image).convert('RGB')\n",
    "        if img.getpixel((0,0)) == (255,255,255):\n",
    "            new_image = img_to_array(img)\n",
    "            if hash(str(new_image[25000:26000])) not in visited:\n",
    "                shirts.append(new_image)\n",
    "            else:\n",
    "                doubles.append(new_image)\n",
    "# print(len(doubles)) # I did this to make sure my hash method for finding doubles wasn't catching too many images\n",
    "# Its length was 16 so I am pretty sure it worked fine\n",
    "# We have 355 jersey images and 297 shirt images. That is pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sorengran/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Classify the data\n",
    "raw_data = [(row,'1') for row in jerseys] + [(row,'0') for row in shirts]\n",
    "\n",
    "# Break into X, y\n",
    "data = np.array([x for (x,y) in raw_data])\n",
    "labels = np.array([y for (x,y) in raw_data])\n",
    "\n",
    "# Scale the data - this didn't have much result so I will leave my data unscaled in general\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use this function to analyze my results\n",
    "# Loosely taken from https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "# Obviously the Recall is the same as the True Positive rate but I included them both separately because it seemed clearer\n",
    "def tfpn(y_true, y_pred):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i] == '1':\n",
    "            tp += 1\n",
    "        elif y_pred[i] == '1' and y_pred[i] != y_true[i]:\n",
    "            fp += 1\n",
    "        elif y_pred[i] == y_true[i] == '0':\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    print('True positive rate = ', tp/(fn+tp))\n",
    "    print('False positive rate = ', fp/(tn+fp))\n",
    "    print('True negative rate = ', tn/(tn+fp))\n",
    "    print('False negative rate = ', fn/(fn+tp))\n",
    "    print('Precision = ', tp/(fp+tp))\n",
    "    print('Recall = ', tp/(tp+fn))\n",
    "    print('Accuracy = ', (tp+tn)/len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data statistics\n",
      "True positive rate =  1.0\n",
      "False positive rate =  0.0\n",
      "True negative rate =  1.0\n",
      "False negative rate =  0.0\n",
      "Precision =  1.0\n",
      "Recall =  1.0\n",
      "Accuracy =  1.0\n",
      "    \n",
      "Test data statistics\n",
      "True positive rate =  0.6460176991150443\n",
      "False positive rate =  0.30120481927710846\n",
      "True negative rate =  0.6987951807228916\n",
      "False negative rate =  0.35398230088495575\n",
      "Precision =  0.7448979591836735\n",
      "Recall =  0.6460176991150443\n",
      "Accuracy =  0.6683673469387755\n"
     ]
    }
   ],
   "source": [
    "# Basic Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "train_predictions = logistic_model.predict(X_train)\n",
    "predictions = logistic_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Unscaled Data results\n",
    "# Train data accuracy score: 1.0\n",
    "# Test data accuracy score: .668\n",
    "# Scaled Data results\n",
    "# Train data accuracy score: 1.0\n",
    "# Test data accuracy score: .694\n",
    "\n",
    "print(\"Train data statistics\")\n",
    "tfpn(y_train, train_predictions)\n",
    "print('    ')\n",
    "print(\"Test data statistics\")\n",
    "tfpn(y_test, predictions)\n",
    "\n",
    "# Obviously we should do well on the data on which we trained our model.\n",
    "# I didn't expect our logistic model to do very well because we have so many dimensions and only around 500 observations\n",
    "# This means that the logistic model would have a hard time fitting the data based on all the dimensions,\n",
    "# since we know that we can't expect a regression model to work well when len(data) < 2^dimensions\n",
    "# Hopefully many of the dimensions are constant because of white backgrounds but there are still many dimensions.\n",
    "# I am surprised we achieved almost 70% accuracy for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data results for 15 components\n",
      "True positive rate =  0.6859504132231405\n",
      "False positive rate =  0.2570093457943925\n",
      "True negative rate =  0.7429906542056075\n",
      "False negative rate =  0.3140495867768595\n",
      "Precision =  0.751131221719457\n",
      "Recall =  0.6859504132231405\n",
      "Accuracy =  0.7127192982456141\n",
      "   \n",
      "Test data results for 15 components\n",
      "True positive rate =  0.5486725663716814\n",
      "False positive rate =  0.26506024096385544\n",
      "True negative rate =  0.7349397590361446\n",
      "False negative rate =  0.45132743362831856\n",
      "Precision =  0.7380952380952381\n",
      "Recall =  0.5486725663716814\n",
      "Accuracy =  0.6275510204081632\n",
      "   \n",
      "Training data results for 30 components\n",
      "True positive rate =  0.7396694214876033\n",
      "False positive rate =  0.16355140186915887\n",
      "True negative rate =  0.8364485981308412\n",
      "False negative rate =  0.2603305785123967\n",
      "Precision =  0.8364485981308412\n",
      "Recall =  0.7396694214876033\n",
      "Accuracy =  0.7850877192982456\n",
      "   \n",
      "Test data results for 30 components\n",
      "True positive rate =  0.48672566371681414\n",
      "False positive rate =  0.39759036144578314\n",
      "True negative rate =  0.6024096385542169\n",
      "False negative rate =  0.5132743362831859\n",
      "Precision =  0.625\n",
      "Recall =  0.48672566371681414\n",
      "Accuracy =  0.5357142857142857\n",
      "   \n",
      "Training data results for 45 components\n",
      "True positive rate =  0.756198347107438\n",
      "False positive rate =  0.1822429906542056\n",
      "True negative rate =  0.8177570093457944\n",
      "False negative rate =  0.24380165289256198\n",
      "Precision =  0.8243243243243243\n",
      "Recall =  0.756198347107438\n",
      "Accuracy =  0.7850877192982456\n",
      "   \n",
      "Test data results for 45 components\n",
      "True positive rate =  0.49557522123893805\n",
      "False positive rate =  0.3855421686746988\n",
      "True negative rate =  0.6144578313253012\n",
      "False negative rate =  0.504424778761062\n",
      "Precision =  0.6363636363636364\n",
      "Recall =  0.49557522123893805\n",
      "Accuracy =  0.5459183673469388\n",
      "   \n",
      "Training data results for 196 components\n",
      "True positive rate =  1.0\n",
      "False positive rate =  0.0\n",
      "True negative rate =  1.0\n",
      "False negative rate =  0.0\n",
      "Precision =  1.0\n",
      "Recall =  1.0\n",
      "Accuracy =  1.0\n",
      "   \n",
      "Test data results for 196 components\n",
      "True positive rate =  0.45132743362831856\n",
      "False positive rate =  0.4578313253012048\n",
      "True negative rate =  0.5421686746987951\n",
      "False negative rate =  0.5486725663716814\n",
      "Precision =  0.5730337078651685\n",
      "Recall =  0.45132743362831856\n",
      "Accuracy =  0.4897959183673469\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "for i in [15, 30, 45, 196]: # We want to try different dimensional reduction to see which works\n",
    "    pca = PCA(n_components = i) # Changing the components \n",
    "    PCA_train = pca.fit_transform(X_train)\n",
    "    PCA_test = pca.fit_transform(X_test)\n",
    "    logistic_model.fit(PCA_train, y_train)\n",
    "    PCA_train_predictions = logistic_model.predict(PCA_train)\n",
    "    PCA_test_predictions = logistic_model.predict(PCA_test)\n",
    "    print('Training data results for %s components' % i)\n",
    "    tfpn(y_train, PCA_train_predictions)\n",
    "    print('   ')\n",
    "    print('Test data results for %s components' % i)\n",
    "    tfpn(y_test, PCA_test_predictions)\n",
    "    print('   ')\n",
    "\n",
    "\n",
    "# Scaled Data results (train results, test results) (accuracy)\n",
    "# n_components = 15: 0.7258771929824561, 0.49489795918367346\n",
    "# n_components = 30: 0.7850877192982456, 0.4897959183673469\n",
    "# n_components = 45: 0.793859649122807, 0.5561224489795918\n",
    "# n_components = 196: 1, 0.5102040816326531\n",
    "\n",
    "# Unscaled Data results (train results, test results) (accuracy)\n",
    "# n_components = 15: 0.7149122807017544, 0.6326530612244898\n",
    "# n_components = 30: 0.7850877192982456, 0.5408163265306123\n",
    "# n_components = 45: 0.7807017543859649, 0.5408163265306123\n",
    "# n_components = 196: 1.0, 0.5306122448979592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sorengran/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data statistics\n",
      "True positive rate =  0.9710743801652892\n",
      "False positive rate =  0.03271028037383177\n",
      "True negative rate =  0.9672897196261683\n",
      "False negative rate =  0.028925619834710745\n",
      "Precision =  0.9710743801652892\n",
      "Recall =  0.9710743801652892\n",
      "Accuracy =  0.9692982456140351\n",
      "    \n",
      "test data statistics\n",
      "True positive rate =  0.6814159292035398\n",
      "False positive rate =  0.3132530120481928\n",
      "True negative rate =  0.6867469879518072\n",
      "False negative rate =  0.3185840707964602\n",
      "Precision =  0.7475728155339806\n",
      "Recall =  0.6814159292035398\n",
      "Accuracy =  0.6836734693877551\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "# Code taken from http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "train, test = clf.transform(X_train), clf.transform(X_test)\n",
    "\n",
    "logistic_model.fit(train, y_train)\n",
    "train_predictions = logistic_model.predict(train)\n",
    "print('train data statistics')\n",
    "tfpn(y_train, train_predictions)\n",
    "print('    ')\n",
    "\n",
    "predictions = logistic_model.predict(test)\n",
    "print('test data statistics')\n",
    "tfpn(y_test, predictions)\n",
    "\n",
    "\n",
    "# Transforming the data then running logistic regression and using LDA's predict are the same thing\n",
    "# LDA_test_predictions = clf.predict(X_test)\n",
    "# LDA_train_predictions = clf.predict(X_train)\n",
    "# tfpn(y_test, LDA_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary:\n",
    "### Logistic Regression\n",
    "|data |TP rate|FP rate|TN rate|FN rate|Precision|Recall|Accuracy|\n",
    "|-----|-------|-------|-------|-------|---------|------|--------|\n",
    "|Train|1.0    |0.0    |1.0    |0.0    |1.0      |1.0   |1.0     |\n",
    "|Test |.646   |.301   |.699   |.354   |.745     |.646  |.668    |\n",
    "\n",
    "\n",
    "### PCA\n",
    "|data |number of components|TP rate|FP rate|TN rate|FN rate|Precision|Recall|Accuracy|\n",
    "|-----|-------------------|-------|-------|-------|-------|---------|------|--------|\n",
    "|Train|15                 |.661   |.224   |.776   |.339   |.769     |.661  |.715    |\n",
    "|Train|30                 |.740   |.159   |.841   |.260   |.840     |.740  |.787    |\n",
    "|Train|45                 |.740   |.159   |.841   |.260   |.840     |.740  |.787    |\n",
    "|Train|196                |1.0    |0.0    |1.0    |0.0    |1.0      |1.0   |1.0     |\n",
    "|Test |15                 |.531   |.229   |.771   |.469   |.759     |.531  |.633    |\n",
    "|Test |30                 |.540   |.337   |.663   |.460   |.685     |.540  |.592    |\n",
    "|Test |45                 |.522   |.373   |.627   |.478   |.656     |.522  |.566    |\n",
    "|Test |196                |.504   |.434   |.566   |.496   |.613     |.504  |.531    |\n",
    "\n",
    "### LDA\n",
    "|data |TP rate|FP rate|TN rate|FN rate|Precision|Recall|Accuracy|\n",
    "|-----|-------|-------|-------|-------|---------|------|--------|\n",
    "|Train|.971   |.033   |.967   |.029   |.971     |.971  |.969    |\n",
    "|Test |.681   |.313   |.687   |.319   |.748     |.681  |.684    |\n",
    "\n",
    "\n",
    "## Reflection\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What did I see in my results? PCA did not perform very well, with a maximum performance with 30 components that was well below Logistic Regression and LDA. LDA and Logistic Regression had almost the same performance, with LDA edging Logistic Regression in Precision, Accuracy, and Recall. What does this mean? Why would we expect these results?  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The major difference between PCA and LDA is that PCA is unsupervised while LDA is supervised. In training, this means that PCA tries to find out what makes a picture a picture. Unfortunately, given our data set, this didn't work. I think this would work better for data where each variable is always relevant in the same way, like financial data with a high number of dimensions. In our data, which were actually the colors of pixels, a given pixel could represent the color of the shirt in one image but then represent the background in the next. I think this prevented PCA from gaining a good understanding of what makes a shirt or a jersey.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LDA is a supervised algorithm. This means that given X, y data, LDA will try to figure out what separates y=1 and y=0. I think this better suited our problem since the data is not really comprehensible. One could look at a lot of financial data and probably make conclusions because credit score is always credit score. But in this data, pixel #23345 was sometimes the shirt, the lapel, the background, the collar, the design, or anything. So instead of trying to understand what that pixel meant, it was smarter to just try to differentiate between a shirt and a jersey.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I also think what may have contributed was my selection of photos with a white background during data cleaning. PCA considered the backgrounds for both shirts and jerseys so it would have considered white backgrounds as being part of both shirts and jerseys, I think. This may have made it harder to tell shirts and jerseys apart because they all looked relatively similar given the same backgrounds. This technique probably helped LDA, though. If all the backgrounds were white, then this did not differentiate shirts and jerseys so LDA would probably not focus on the background. This meant that it would probably focus on the center of the image where the shirt/jersey hopefully was. I think Logistic Regression would have a similar approach as LDA which is probably why it also outperformed PCA.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
